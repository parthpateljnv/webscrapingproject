{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "scraping-final-github-topics-repositories.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.6"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/parthpateljnv/webscrapingproject/blob/main/scraping_final_github_topics_repositories.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7bKUKkazS3Ri"
      },
      "source": [
        "# Scraping Top Repositories for Topics on GitHub\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8EK6lRkzS3Rk"
      },
      "source": [
        "Here are the steps we'll follow:\n",
        "\n",
        "- We're going to scrape https://github.com/topics\n",
        "- We'll get a list of topics. For each topic, we'll get topic title, topic page URL and topic description\n",
        "- For each topic, we'll get the top 25 repositories in the topic from the topic page\n",
        "- For each repository, we'll grab the repo name, username, stars and repo URL\n",
        "- For each topic we'll create a CSV file in the following format:\n",
        "\n",
        "```\n",
        "Repo Name,Username,Stars,Repo URL\n",
        "three.js,mrdoob,69700,https://github.com/mrdoob/three.js\n",
        "libgdx,libgdx,18300,https://github.com/libgdx/libgdx\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qJcit0f2S3Rl"
      },
      "source": [
        "## Scrape the list of topics from Github\n",
        "\n",
        "Steps:\n",
        "\n",
        "- use requests to downlaod the page\n",
        "- user BS4 to parse and extract information\n",
        "- convert to a Pandas dataframe\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TDA8IqidS3Rm"
      },
      "source": [
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "\n",
        "def get_topics_page():\n",
        "    # TODO - add comments\n",
        "    topics_url = 'https://github.com/topics'\n",
        "    response = requests.get(topics_url)\n",
        "    if response.status_code != 200:\n",
        "        raise Exception('Failed to load page {}'.format(topic_url))\n",
        "    doc = BeautifulSoup(response.text, 'html.parser')\n",
        "    return doc"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gvNoBzhdTVVK"
      },
      "source": [
        "import pandas as pd\n",
        "import os"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Sq8FDcSnTVFC"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ob2MyE9AS3Rn"
      },
      "source": [
        "Add some explanation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uoJ9N4EXS3Ro"
      },
      "source": [
        "doc = get_topics_page()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c-jAUozeS3Rp"
      },
      "source": [
        "\n",
        "\n",
        "To get topic titles, we can pick `p` tags with the `class` ...\n",
        "\n",
        "![](https://i.imgur.com/OnzIdyP.png)\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "idFL7qGJS3Rq"
      },
      "source": [
        "def get_topic_titles(doc):\n",
        "    selection_class = 'f3 lh-condensed mb-0 mt-1 Link--primary'\n",
        "    topic_title_tags = doc.find_all('p', {'class': selection_class})\n",
        "    topic_titles = []\n",
        "    for tag in topic_title_tags:\n",
        "        topic_titles.append(tag.text)\n",
        "    return topic_titles"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2vD2EMlxS3Rs"
      },
      "source": [
        "`get_topic_titles` can be used to get the list of titles"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Im1tqv1ES3Rt"
      },
      "source": [
        "titles = get_topic_titles(doc)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9N1O3XEkS3Rt",
        "outputId": "dfd75ace-b6a1-49ab-e7f4-72d942047a24"
      },
      "source": [
        "len(titles)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "30"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Rw8WVnMeS3Rx",
        "outputId": "5b51e922-eaf2-481e-edfb-f7c2fb7d27f7"
      },
      "source": [
        "titles[:5]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['3D', 'Ajax', 'Algorithm', 'Amp', 'Android']"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aKxLc52hS3Ry"
      },
      "source": [
        "Similarly we have defined functions for descriptions and URLs."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j3UKzw2XS3Rz"
      },
      "source": [
        "def get_topic_descs(doc):\n",
        "    desc_selector = 'f5 color-text-secondary mb-0 mt-1'\n",
        "    topic_desc_tags = doc.find_all('p', {'class': desc_selector})\n",
        "    topic_descs = []\n",
        "    for tag in topic_desc_tags:\n",
        "        topic_descs.append(tag.text.strip())\n",
        "    return topic_descs\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q3rbHzPlS3R0"
      },
      "source": [
        "function to get the ulf for each topic"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1-yHiUpVS3R0"
      },
      "source": [
        "def get_topic_urls(doc):\n",
        "    topic_link_tags = doc.find_all('a', {'class': 'd-flex no-underline'})\n",
        "    topic_urls = []\n",
        "    base_url = 'https://github.com'\n",
        "    for tag in topic_link_tags:\n",
        "        topic_urls.append(base_url + tag['href'])\n",
        "    return topic_urls\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5aSM73lqS3R3"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Soug6M3TS3R4"
      },
      "source": [
        "after  putting  this all together into a single\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zztRf7J0S3R4"
      },
      "source": [
        "def scrape_topics():\n",
        "    topics_url = 'https://github.com/topics'\n",
        "    response = requests.get(topics_url)\n",
        "    if response.status_code != 200:\n",
        "        raise Exception('Failed to load page {}'.format(topics_url))\n",
        "    doc = BeautifulSoup(response.text, 'html.parser')\n",
        "    topics_dict = {\n",
        "        'title': get_topic_titles(doc),\n",
        "        'description': get_topic_descs(doc),\n",
        "        'url': get_topic_urls(doc)\n",
        "    }\n",
        "    \n",
        "    return pd.DataFrame(topics_dict)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l3TYSpmgS3R9"
      },
      "source": [
        "## Get the top 25 repositories from a topic page\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "asTPPLb8S3R-"
      },
      "source": [
        "def get_topic_page(topic_url):\n",
        "    # Download the page\n",
        "    response = requests.get(topic_url)\n",
        "    # Check successful response\n",
        "    if response.status_code != 200:\n",
        "        raise Exception('Failed to load page {}'.format(topic_url))\n",
        "    # Parse using Beautiful soup\n",
        "    topic_doc = BeautifulSoup(response.text, 'html.parser')\n",
        "    return topic_doc\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ktC7XvWoS3R_"
      },
      "source": [
        "doc = get_topic_page('https://github.com/topics/3d')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BRNf__B3S3R_"
      },
      "source": [
        "h1_tag contans repo username and reponame and star_tags contas star information"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tGHhc_oRaeKb"
      },
      "source": [
        "base_url = \"https://github.com\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a1YtGx1-bBEV"
      },
      "source": [
        "#def parse_star_count()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JX6Au60sS3SA"
      },
      "source": [
        "def get_repo_info(h1_tag, star_tag):\n",
        "    # returns all the required info about a repository\n",
        "    a_tags = h1_tag.find_all('a')\n",
        "    username = a_tags[0].text.strip()\n",
        "    repo_name = a_tags[1].text.strip()\n",
        "    repo_url =  base_url + a_tags[1]['href']\n",
        "    stars = star_tag.text.strip()\n",
        "    return username, repo_name, stars, repo_url"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "65fCKF_WS3SC"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NFXzIWk_S3SD"
      },
      "source": [
        "def get_topic_repos(topic_doc):\n",
        "    # Get the h1 tags containing repo title, repo URL and username\n",
        "    h1_selection_class = 'f3 color-text-secondary text-normal lh-condensed'\n",
        "    repo_tags = topic_doc.find_all('h3', {'class': h1_selection_class} )\n",
        "    # Get star tags\n",
        "    star_tags = topic_doc.find_all('a', { 'class': 'social-count float-none'})\n",
        "    \n",
        "    topic_repos_dict = { 'username': [], 'repo_name': [], 'stars': [],'repo_url': []}\n",
        "    #print(repo_tags)\n",
        "    #print(star_tags)\n",
        "    # Get repo info\n",
        "    for i in range(len(repo_tags)):\n",
        "        repo_info = get_repo_info(repo_tags[i], star_tags[i])\n",
        "        topic_repos_dict['username'].append(repo_info[0])\n",
        "        topic_repos_dict['repo_name'].append(repo_info[1])\n",
        "        topic_repos_dict['stars'].append(repo_info[2])\n",
        "        topic_repos_dict['repo_url'].append(repo_info[3])\n",
        "    \n",
        "    return pd.DataFrame(topic_repos_dict)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tdAVCfG7S3SG"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3xQRzzM1S3SG"
      },
      "source": [
        "def scrape_topic(topic_url, path):\n",
        "    if os.path.exists(path):\n",
        "        print(\"The file {} already exists. Skipping...\".format(path))\n",
        "        return\n",
        "    topic_df = get_topic_repos(get_topic_page(topic_url))\n",
        "    #print(topic_df)\n",
        "    topic_df.to_csv(path, index=None)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0hS_m8GJS3SH"
      },
      "source": [
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mRYbDdOIS3SH"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ObhhPsw3S3SH"
      },
      "source": [
        "## Putting it all together\n",
        "\n",
        "- We have a funciton to get the list of topics\n",
        "- We have a function to create a CSV file for scraped repos from a topics page\n",
        "- Let's create a function to put them together"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HaSty9wyS3SI"
      },
      "source": [
        "def scrape_topics_repos():\n",
        "    print('Scraping list of topics')\n",
        "    topics_df = scrape_topics()\n",
        "    \n",
        "    #os.makedirs('data', exist_ok=True)\n",
        "    for index, row in topics_df.iterrows():\n",
        "       # print('Scraping top repositories for \"{}\"'.format(row['title']))\n",
        "        scrape_topic(row['url'], '{}.csv'.format(row['title']))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fbhcoGc-S3SP"
      },
      "source": [
        "Let's run it to scrape the top repos for the all the topics on the first page of https://github.com/topics"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HZlKwzHtT86K"
      },
      "source": [
        "base_url = \"https://github.com\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "foGrQvUCS3SQ",
        "outputId": "933b35dd-1f01-4301-9f33-c36320db1f14"
      },
      "source": [
        "scrape_topics_repos()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Scraping list of topics\n",
            "The file 3D.csv already exists. Skipping...\n",
            "The file Ajax.csv already exists. Skipping...\n",
            "The file Algorithm.csv already exists. Skipping...\n",
            "The file Amp.csv already exists. Skipping...\n",
            "The file Android.csv already exists. Skipping...\n",
            "The file Angular.csv already exists. Skipping...\n",
            "The file Ansible.csv already exists. Skipping...\n",
            "The file API.csv already exists. Skipping...\n",
            "The file Arduino.csv already exists. Skipping...\n",
            "The file ASP.NET.csv already exists. Skipping...\n",
            "The file Atom.csv already exists. Skipping...\n",
            "The file Awesome Lists.csv already exists. Skipping...\n",
            "The file Amazon Web Services.csv already exists. Skipping...\n",
            "The file Azure.csv already exists. Skipping...\n",
            "The file Babel.csv already exists. Skipping...\n",
            "The file Bash.csv already exists. Skipping...\n",
            "The file Bitcoin.csv already exists. Skipping...\n",
            "The file Bootstrap.csv already exists. Skipping...\n",
            "The file Bot.csv already exists. Skipping...\n",
            "The file C.csv already exists. Skipping...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "agr8LLBDS3SQ"
      },
      "source": [
        "We can check that the CSVs were created properly"
      ]
    }
  ]
}